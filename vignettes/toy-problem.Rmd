---
title: Toy example of poridge
author: Phil Reiss & David L Miler

---

First load up `poridge` and `mgcv`

```{r}
require(mgcv)
require(poridge)
```

Set the seed...

```{r}
set.seed(813)
```

Generate some data

```{r}
Xnl <- matrix(0,30,101)
tt <- sort(sample(1:90,30))
for (i in 1:30) {
  Xnl[i, tt[i]:(tt[i]+4)] <- -1
  Xnl[i, (tt[i]+5):(tt[i]+9)] <- 1
}
X.toy <- Xnl + matrix(rnorm(30*101,,.05),30)

# response
y.toy <- tt + rnorm(30,.05)

# dummy data to go in the s() call
dummy <- 1:30
```

We can plot the data

```{r fig.width=10}
par(mfrow=c(1,3))

matplot((0:100)/100, t(Xnl[c(4,25), ]), type="l", xlab="t", ylab="",
        ylim=range(X.toy), main="Noiseless functions")

matplot((0:100)/100, t(X.toy[c(4,25), ]), type="l", xlab="t", ylab="",
        ylim=range(X.toy), main="Observed functions")

y.rainbow <- rainbow(30, end=0.9)[(y.toy-min(y.toy))/diff(range(y.toy))*29+1]

matplot((0:100)/100, t(X.toy), type="l", lty=1, col=y.rainbow,
        xlab="t", ylab="", main="Rainbow plot")
```

Now calculating the DTW distance

```{r}
require(dtw)
D <- dist(X.toy, method="dtw", window.type="sakoechiba", window.size=5)
```


Here we fit a series of models with different projection dimensions from 1 to 15 and store the GCV scores. For each projection dimension we fit two models, one using the distances calculated from `dist` in R (`m1`) and one with DTW distance calculated above (`m2`).

```{r}
GCVmat <- matrix(NA, 15, 2)

for(k. in 1:15){
  m1 <- gam(y.toy ~ s(dummy, bs="pco", k=k., xt=list(realdata=X.toy, dist_fn=dist)), method="REML")
  m2 <- gam(y.toy ~ s(dummy, bs="pco", k=k., xt=list(D=D)), method="REML")

  GCVmat[k., ] <- length(y.toy) * c(sum(m1$residuals^2)/m1$df.residual^2,
                                    sum(m2$residuals^2)/m2$df.residual^2)
}
```

Now plotting the GCV scores

```{r}
matplot(GCVmat, lty=1, col=1:2, pch=16, type="o")
legend("bottomleft", c("PCR", "DTW-based PCoR"), lty=1, col=1:2, pch=16, cex=1.5)
```

Which was the best DTW model?

```{r}
which.min(GCVmat[,2])
```

So, refitting the model with projection dimension 11:

```{r}
m2 <- gam(y.toy ~ s(dummy, bs="pco", k=11, xt=list(D=D)), method="REML")
summary(m2)
```



## What if `add=FALSE`

By default we set `add=TRUE` in the MDS step, adding a constant to the distance matrix if necessary to ensure that it is Euclidean (see `?cmdscale`). Let's see what happens when we turn that option off:


```{r}
GCVmat_add <- matrix(NA, 15, 2)

for (k. in 1:15) {
    m1 <- gam(y.toy ~ s(dummy, bs="pco", k=k.,
                        xt=list(realdata=X.toy, dist_fn=dist, add=FALSE)), method="REML")
    m2 <- gam(y.toy ~ s(dummy, bs="pco", k=k., xt=list(D=D, add=FALSE)), method="REML")

    GCVmat_add[k., ] = length(y.toy) * c(sum(m1$residuals^2)/m1$df.residual^2,
                                         sum(m2$residuals^2)/m2$df.residual^2)
}
```

and plotting those results


```{r}
matplot(GCVmat_add, lty=1, col=1:2, pch=16, type="o")
legend("bottomleft", c("PCR", "DTW-based PCoR"), lty=1, col=1:2, pch=16, cex=1.5)
```

```{r}
m2_add <- gam(y.toy ~ s(dummy, bs="pco", k=which.min(GCVmat[,2]), xt=list(D=D, add=FALSE)), method="REML")
summary(m2_add)
```

There doesn't seem to be a difference.
